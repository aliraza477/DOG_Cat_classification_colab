{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjE0N7ieM2We",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "00ca9afb-ad5a-425a-9dd7-caed06e8e7aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eifdG9ntNUec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6201bb28-0662-4102-edb2-419dffe09ac1"
      },
      "source": [
        "import os\n",
        "PROJECT_DIRECTORY = os.path.join(os.getcwd(), 'gdrive', 'My Drive','CNN10','checkpoint1.pth')\n",
        "print(PROJECT_DIRECTORY)\n",
        "os.makedirs(os.path.dirname(PROJECT_DIRECTORY))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/CNN10/checkpoint1.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS7Q3HFBUboh",
        "colab_type": "code",
        "outputId": "643ebf1e-d6b0-4cab-de46-8abe59e2423b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python2.7/dist-packages (1.3.1+cu100)\n",
            "Requirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python2.7/dist-packages (0.4.2+cu100)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.16.4)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.3.1+cu100)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python2.7/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from torch==1.3.1->torchvision) (0.16.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python2.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.16.4)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.post1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.3.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.6)\n",
            "Requirement already satisfied: functools32>=3.2.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (3.2.3.post2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Installing collected packages: tensorflow-estimator\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "Successfully installed tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiSSeNGUUwzT",
        "colab_type": "code",
        "outputId": "fd819795-84b3-4505-a1b8-9b300f4a5d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget -c https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
        "!unzip -qq Cat_Dog_data.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-30 17:18:47--  https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.96.237\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.96.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580495262 (554M) [application/zip]\n",
            "Saving to: ‘Cat_Dog_data.zip’\n",
            "\n",
            "Cat_Dog_data.zip    100%[===================>] 553.60M  26.5MB/s    in 21s     \n",
            "\n",
            "2019-12-30 17:19:08 (26.1 MB/s) - ‘Cat_Dog_data.zip’ saved [580495262/580495262]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbqYRcbiU4Qs",
        "colab_type": "code",
        "outputId": "c649204d-a816-4aec-87fc-a23385669399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(root=\"./Cat_Dog_data\", transform=transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()]))\n",
        "def get_subset(indices, start, end):\n",
        "    return indices[start : start + end]\n",
        "\n",
        "\n",
        "TRAIN_PCT, VALIDATION_PCT = 0.6, 0.2  # rest will go for test\n",
        "train_count = int(len(dataset) * TRAIN_PCT)\n",
        "validation_count = int(len(dataset) * VALIDATION_PCT)\n",
        "print(validation_count)\n",
        "\n",
        "indices = torch.randperm(len(dataset))\n",
        "\n",
        "train_indices = get_subset(indices, 0, train_count)\n",
        "print(train_indices.shape)\n",
        "validation_indices = get_subset(indices, train_count, validation_count)\n",
        "print(validation_indices.shape)\n",
        "test_indices = get_subset(indices, train_count + validation_count, len(dataset))\n",
        "print(test_indices.shape)\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    \"train\": torch.utils.data.DataLoader(\n",
        "        dataset, sampler=SubsetRandomSampler(train_indices), batch_size=16 \n",
        "    ),\n",
        "    \"validation\": torch.utils.data.DataLoader(\n",
        "        dataset, sampler=SubsetRandomSampler(validation_indices),batch_size=16\n",
        "    ),\n",
        "    \"test\": torch.utils.data.DataLoader(\n",
        "        dataset, sampler=SubsetRandomSampler(test_indices),batch_size=16\n",
        "    ),\n",
        "}\n",
        "torch.utils.data.DataLoader"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "torch.Size([15000])\n",
            "torch.Size([5000])\n",
            "torch.Size([5000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIOBNnVLmBVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU())\n",
        "            \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU())\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=  1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())   \n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU() )\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
        "            #torch.nn.Dropout(0.2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU())\n",
        "        self.fc = nn.Linear(16*8*8, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        out = self.layer1(x)\n",
        "        #print(out.shape)\n",
        "        out = self.layer2(out)\n",
        "       # print(out.shape)\n",
        "        out=self.layer3(out)\n",
        "       # print(out.shape)\n",
        "        out=self.layer4(out)\n",
        "       # print(out.shape)\n",
        "        out=self.layer5(out)\n",
        "        #print(out.shape)\n",
        "        out=self.layer6(out)\n",
        "       # print(out.shape)\n",
        "        out=self.layer7(out)\n",
        "       # print('out7',out.shape)\n",
        "        out=self.layer8(out)\n",
        "        #print('out8',out.shape)\n",
        "        out=self.layer9(out)\n",
        "       # print(out.shape)\n",
        "       \n",
        "        #print(out.shape)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2LsSDTP4RtZ",
        "colab_type": "code",
        "outputId": "d4bca408-71f2-424f-e3b6-a4474cbf8e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Device configuration\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "from __future__ import division\n",
        "# Hyper parameters\n",
        "num_epochs = 10\n",
        "num_classes = 2\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "model = ConvNet(num_classes).to(device)\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "trainaccuracies = []\n",
        "validationaccuracies = []\n",
        "# Train the model\n",
        "total_step = len(dataloaders['train'])\n",
        "for epoch in range(num_epochs):\n",
        "    total=0\n",
        "    correct = 0\n",
        "    train_acc=0\n",
        "    train_hist=[]\n",
        "    for i, (images, labels) in enumerate(dataloaders['train']):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        train_hist.append(loss)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "#        if (i+1) % 100 == 0:\n",
        "#            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "#                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "    train_acc=(correct/total)*100\n",
        "    trainaccuracies.append(train_acc)\n",
        "    print ('Epoch [{}/{}], Train Loss: {:.4f}, train Acc: {:,.4f}'\n",
        "                   .format(epoch+1, num_epochs, loss.item(), train_acc))\n",
        "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_acc=0\n",
        "        val_hist=[]\n",
        "        for images, labels in dataloaders['validation']:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            val_hist.append(loss)\n",
        "        val_acc=(correct/total)*100\n",
        "        validationaccuracies.append(val_acc)\n",
        "        print ('Epoch [{}/{}], Val Loss: {:.4f} , Val Acc: {:,.4f}'\n",
        "                   .format(epoch+1, num_epochs, loss.item(), val_acc))\n",
        "\n",
        "torch.save(model.cpu().state_dict(), PROJECT_DIRECTORY) \n",
        "        \n",
        "           "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Train Loss: 0.5164, train Acc: 89.9333\n",
            "Epoch [1/10], Val Loss: 0.1052 , Val Acc: 90.4600\n",
            "Epoch [2/10], Train Loss: 0.3793, train Acc: 89.9867\n",
            "Epoch [2/10], Val Loss: 0.3777 , Val Acc: 90.4600\n",
            "Epoch [3/10], Train Loss: 0.1011, train Acc: 89.9867\n",
            "Epoch [3/10], Val Loss: 0.1027 , Val Acc: 90.4600\n",
            "Epoch [4/10], Train Loss: 0.6505, train Acc: 89.9867\n",
            "Epoch [4/10], Val Loss: 0.3786 , Val Acc: 90.4600\n",
            "Epoch [5/10], Train Loss: 0.3799, train Acc: 89.9867\n",
            "Epoch [5/10], Val Loss: 0.3794 , Val Acc: 90.4600\n",
            "Epoch [6/10], Train Loss: 0.1055, train Acc: 89.9867\n",
            "Epoch [6/10], Val Loss: 0.1035 , Val Acc: 90.4600\n",
            "Epoch [7/10], Train Loss: 0.3821, train Acc: 89.9867\n",
            "Epoch [7/10], Val Loss: 0.3819 , Val Acc: 90.4600\n",
            "Epoch [8/10], Train Loss: 0.8962, train Acc: 89.9867\n",
            "Epoch [8/10], Val Loss: 0.3770 , Val Acc: 90.4600\n",
            "Epoch [9/10], Train Loss: 0.3790, train Acc: 89.9867\n",
            "Epoch [9/10], Val Loss: 0.1122 , Val Acc: 90.4600\n",
            "Epoch [10/10], Train Loss: 0.0983, train Acc: 89.9867\n",
            "Epoch [10/10], Val Loss: 0.0985 , Val Acc: 90.4600\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}